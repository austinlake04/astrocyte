{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import rawpy\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from astropy.nddata import CCDData\n",
    "# from astropy.stats import mad_std\n",
    "# import ccdproc as ccdp\n",
    "\n",
    "# test data sourced from https://www.reddit.com/r/astrophotography/comments/9q7tum/andromeda_galaxy_raw_photos_to_experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "CURRENT_DIR = os.path.dirname(os.path.realpath('__file__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_image(calibrated_image: np.ndarray[np.uint16], features: tuple, base_features: tuple, detector_type: str, match_percent_threshhold: float=0.8) -> np.ndarray[int]:\n",
    "    \"\"\"Registers and aligned an image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    calibrated_image: numpy.ndarray[numpy.uint16]\n",
    "        Calibrated image\n",
    "    \n",
    "    features: tuple\n",
    "        Keypoints and descriptors from features of interest for current image\n",
    "    \n",
    "    base_features: tuple\n",
    "        Keypoints and descriptors for features of interest of base image\n",
    "    \n",
    "    match_percent_threshhold: float\n",
    "        Percentage threshold of matches to include in registration process\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    registered_image: numpy.ndarray[numpy.uint16]\n",
    "        Registered image\n",
    "    \"\"\"    \n",
    "    keypoints, descriptors = features\n",
    "    base_keypoints, base_descriptors = base_features\n",
    "\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) if detector_type != 'SIFT' else cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = matcher.match(descriptors, base_descriptors, None)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    if matcher == 'SIFT':\n",
    "        good_matches = []\n",
    "        for m1, m2 in matches:\n",
    "            if m1.distance < 0.6*m2.distance:\n",
    "                good_matches.append(m1)\n",
    "        matches = good_matches\n",
    "    else:\n",
    "        matches = matches[:int(len(matches)*match_percent_threshhold)]\n",
    "\n",
    "    features = [keypoints, base_keypoints]\n",
    "    points = np.empty((2, len(matches), 2))\n",
    "    for (i, feature) in enumerate(features):\n",
    "        for (j, match) in enumerate(matches):\n",
    "            points[i,j,:] = feature[match.trainIdx if i else match.queryIdx].pt\n",
    "\n",
    "    homography, mask = cv2.findHomography(points[0], points[1], cv2.RANSAC)\n",
    "    registered_image = cv2.warpPerspective(calibrated_image, homography, (calibrated_image.shape[1], calibrated_image.shape[0]))\n",
    "    return registered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration_frames(base_dir: str, use_median: bool=False) -> tuple[np.ndarray[int]]:\n",
    "    \"\"\"Generates calibration frame from a specified image set\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    base_dir: str\n",
    "        Base directory containing image set\n",
    "    \n",
    "    use_median: bool\n",
    "        Determines if median function is used for calibration frame averaging\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    master_bias_frame: numpy.ndarray[numpy.uint16]\n",
    "        Master bias calibration frame\n",
    "\n",
    "    master_dark_frame: numpy.ndarray[numpy.uint16]\n",
    "        Master dark calibration frame\n",
    "    \"\"\"\n",
    "    averaging_func = np.median if use_median else np.mean\n",
    "    \n",
    "    bias_dir = f\"{base_dir}/BIAS\"\n",
    "    bias_frames = []\n",
    "    dark_dir = f\"{base_dir}/DARKS\"\n",
    "    dark_frames = []\n",
    "\n",
    "    try:\n",
    "        for (i, file) in enumerate(os.listdir(bias_dir)):\n",
    "            with rawpy.imread(f\"{bias_dir}/{file}\") as raw:\n",
    "                bias_frames.append(raw.raw_image)\n",
    "        master_bias_frame = averaging_func(np.asarray(bias_frames), axis=0)\n",
    "        for (i, file) in enumerate(os.listdir(dark_dir)):\n",
    "            with rawpy.imread(f\"{dark_dir}/{file}\") as raw:\n",
    "                dark_frames.append(raw.raw_image)\n",
    "        master_dark_frame = averaging_func(np.asarray(dark_frames), axis=0)\n",
    "        return master_bias_frame, master_dark_frame\n",
    "    except rawpy.LibRawError:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_8bit(image: np.ndarray[np.uint16]) -> np.ndarray[np.uint8]:\n",
    "    scaled_image = (image/257).astype(np.uint8)\n",
    "    return scaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_image(image_file_path: str, master_bias_frame: np.ndarray[np.uint16], master_dark_frame: np.ndarray[np.uint16], detector_type) -> np.ndarray[np.uint16]:\n",
    "    \"\"\"Loads and calibrates an image at a specified file path\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    image_file_path: str\n",
    "        Full path to specified image\n",
    "\n",
    "    master_bias_frame: numpy.ndarray[numpy.uint16]\n",
    "        Master bias calibration frame\n",
    "\n",
    "    master_dark_frame: numpy.ndarray[numpy.uint16]\n",
    "        Master dark calibration frame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    calibrated_image: numpy.ndarray[numpy.uint16]\n",
    "        Calibrated image\n",
    "    \n",
    "    keypoints: tuple\n",
    "        Keypoints from features of interest for calibrated image\n",
    "    \n",
    "    descriptors: tuple\n",
    "        Descriptors from features of interest for calibrated image\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with rawpy.imread(image_file_path) as raw:\n",
    "            calibrated_image = 1.0*raw.raw_image - master_dark_frame\n",
    "            calibrated_image[calibrated_image < 0] = 0\n",
    "            calibrated_image = calibrated_image.astype(np.uint16)\n",
    "            np.copyto(raw.raw_image, calibrated_image)\n",
    "\n",
    "            params = rawpy.Params(gamma=(1,1),\n",
    "                                  no_auto_scale=False,\n",
    "                                  no_auto_bright=True,\n",
    "                                  output_bps=16,\n",
    "                                  use_camera_wb=True,\n",
    "                                  use_auto_wb=False,\n",
    "                                  user_wb=None,\n",
    "                                  output_color=rawpy.ColorSpace.sRGB,\n",
    "                                  demosaic_algorithm=rawpy.DemosaicAlgorithm.AHD,\n",
    "                                  fbdd_noise_reduction=rawpy.FBDDNoiseReductionMode.Full,\n",
    "                                  dcb_enhance=False,\n",
    "                                  dcb_iterations=0,\n",
    "                                  half_size=False,\n",
    "                                  median_filter_passes=0,\n",
    "                                  user_black=0)\n",
    "                                  \n",
    "            calibrated_image = raw.postprocess(params)\n",
    "            if detector_type == 'ORB':\n",
    "                detector = cv2.ORB_create()\n",
    "            elif detector_type == 'SIFT':\n",
    "                detector = cv2.SIFT_create()\n",
    "            else:\n",
    "                detector = cv2.AKAZE_create()\n",
    "            keypoints, descriptors = detector.detectAndCompute(scale_to_8bit(calibrated_image), None)\n",
    "            return calibrated_image, keypoints, descriptors\n",
    "    except rawpy.LibRawError:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image_stack: np.ndarray[np.uint16], title: str=\"\") -> None:\n",
    "    \"\"\"Shows image(s)\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    image_stack: numpy.ndarray[numpy.uint16]\n",
    "        Image(s) to be displayed\n",
    "    \n",
    "    title: str\n",
    "        Title of image plot(s)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if len(image_stack.shape) == 4:\n",
    "        num_of_plots = image_stack.shape[0]\n",
    "        fig, ax = plt.subplots(ncols=num_of_plots, figsize=(5*num_of_plots, 5))\n",
    "        plots = []\n",
    "        for (i, image) in enumerate(image_stack):\n",
    "            plots.append(ax[i].imshow(scale_to_8bit(image)))\n",
    "            # fig.colorbar(plots[i], ax=ax[i])\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        plot = ax.imshow(scale_to_8bit(image_stack))\n",
    "        # fig.colorbar(plot, ax=ax)\n",
    "    plt.style.use('dark_background')\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_images(image_set: str) -> np.ndarray[np.uint16]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_set: str\n",
    "        Name of image set to be processed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stacked_image: numpy.ndarray[numpy.uint16]\n",
    "        Stacked image\n",
    "    \"\"\"\n",
    "    global CURRENT_DIR\n",
    "    \n",
    "    base_dir = f\"{CURRENT_DIR}/../data/{image_set}\"\n",
    "    if os.path.isdir(base_dir):\n",
    "\n",
    "        master_bias_frame, master_dark_frame = get_calibration_frames(base_dir)\n",
    "        light_dir = f\"{base_dir}/LIGHTS\"\n",
    "\n",
    "        detector_types = ['SIFT', 'AKAZE', 'ORB']\n",
    "        images = []\n",
    "        for detector_type in detector_types:\n",
    "            for file in os.listdir(light_dir)[0:1]:\n",
    "                stacked_image, base_keypoints, base_descriptors = calibrate_image(image_file_path=f\"{light_dir}/{file}\",\n",
    "                                                                                  master_bias_frame=master_bias_frame,\n",
    "                                                                                  master_dark_frame=master_dark_frame,\n",
    "                                                                                  detector_type=detector_type)\n",
    "            for (i, file) in enumerate(tqdm(os.listdir(light_dir)[1:], desc=f\"{detector_type} stacked image\")):\n",
    "                calibrated_image, keypoints, descriptors = calibrate_image(image_file_path=f\"{light_dir}/{file}\",\n",
    "                                                                           master_bias_frame=master_bias_frame,\n",
    "                                                                           master_dark_frame=master_dark_frame,\n",
    "                                                                           detector_type=detector_type)\n",
    "                registered_image = register_image(calibrated_image,\n",
    "                                                features=(keypoints, descriptors),\n",
    "                                                base_features=(base_keypoints, base_descriptors),\n",
    "                                                detector_type=detector_type)\n",
    "                alpha = 1/(i+1)\n",
    "                beta = 1 - alpha\n",
    "                stacked_image = cv2.addWeighted(registered_image, alpha, stacked_image, beta, 0)\n",
    "            stacked_image = (len(os.listdir(light_dir))*stacked_image)\n",
    "            show(stacked_image, title=f\"{detector_type} stacked image\")\n",
    "            images.append(stacked_image)\n",
    "        return images\n",
    "    else:\n",
    "        print(\"Not a valid image set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stacked_image \u001b[39m=\u001b[39m stack_images(\u001b[39m'\u001b[39;49m\u001b[39mANDROMEDA_TEST\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mstack_images\u001b[0;34m(image_set)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m detector_type \u001b[39min\u001b[39;00m detector_types:\n\u001b[1;32m     25\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(light_dir)[\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]:\n\u001b[0;32m---> 26\u001b[0m         stacked_image, base_keypoints, base_descriptors \u001b[39m=\u001b[39m calibrate_image(image_file_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mlight_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m                                                                           master_bias_frame\u001b[39m=\u001b[39;49mmaster_bias_frame,\n\u001b[1;32m     28\u001b[0m                                                                           master_dark_frame\u001b[39m=\u001b[39;49mmaster_dark_frame,\n\u001b[1;32m     29\u001b[0m                                                                           detector_type\u001b[39m=\u001b[39;49mdetector_type)\n\u001b[1;32m     30\u001b[0m     \u001b[39mfor\u001b[39;00m (i, file) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(os\u001b[39m.\u001b[39mlistdir(light_dir)[\u001b[39m1\u001b[39m:], desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdetector_type\u001b[39m}\u001b[39;00m\u001b[39m stacked image\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m     31\u001b[0m         calibrated_image, keypoints, descriptors \u001b[39m=\u001b[39m calibrate_image(image_file_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlight_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m                                                                    master_bias_frame\u001b[39m=\u001b[39mmaster_bias_frame,\n\u001b[1;32m     33\u001b[0m                                                                    master_dark_frame\u001b[39m=\u001b[39mmaster_dark_frame,\n\u001b[1;32m     34\u001b[0m                                                                    detector_type\u001b[39m=\u001b[39mdetector_type)\n",
      "Cell \u001b[0;32mIn[6], line 50\u001b[0m, in \u001b[0;36mcalibrate_image\u001b[0;34m(image_file_path, master_bias_frame, master_dark_frame, detector_type)\u001b[0m\n\u001b[1;32m     32\u001b[0m np\u001b[39m.\u001b[39mcopyto(raw\u001b[39m.\u001b[39mraw_image, calibrated_image)\n\u001b[1;32m     34\u001b[0m params \u001b[39m=\u001b[39m rawpy\u001b[39m.\u001b[39mParams(gamma\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),\n\u001b[1;32m     35\u001b[0m                       no_auto_scale\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m                       no_auto_bright\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m                       median_filter_passes\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     48\u001b[0m                       user_black\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m calibrated_image \u001b[39m=\u001b[39m raw\u001b[39m.\u001b[39;49mpostprocess(params)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m detector_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mORB\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     52\u001b[0m     detector \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mORB_create()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_image = stack_images('ANDROMEDA_TEST')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('astrocyte')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba8f46737d5e2273531c21d3c9723e3acc9982873706551efeb707acc9da0142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
